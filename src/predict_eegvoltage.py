# -*- coding: utf-8 -*-
"""predict_EEGvoltage

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G6e-SelkB5tR21NZ43xNNfn48zH9vBWN
"""

#import libraries
import os
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from numpy import array
from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense

#source data from Kaggle(required to download from the website)
! pip install kaggle
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download metacosmos/eeg-dataset-recorded-in-a-car-simulator

!cd /content/y
! unzip eeg-dataset-recorded-in-a-car-simulator.zip

#print pandas dataframe
data=pd.read_csv('X_item_1.csv')
#print(type(data))
split=data['-12;-1.5516247;0.53307754;1.4710278;-6.8242185;0.872886;1.7482582;5.843572;3.1885856;-1.5489088;-4.2587052;1.2039108;-3.3919887;2.3924825;3.3319984;-1.5195659;5.9143993;-2.1218342;0.93425862;3.5526886;-0.49939592;0.2716543;-4.8271452;-1.8079899;2.0471965;-0.41194134;-5.4100341;0.76464844;-3.4659315;3.8028669;2.1644446;4.2061085;-4.7557182;1.0973469;0.048977121;-3.6234864;0.37750677'].str.split(';', expand=True)

print(split.shape)
#print(type(split))
display(split)

#user defined function to convert Pandas dataframes to float lists
def convert(pandas_df):
  list = pandas_df.tolist()
  float_lst = []
  for item in list:
    float_lst.append(float(item))
  return(float_lst)

#data visualization(voltage signal vs time)
times = split.iloc[:, 0]
times_converted=convert(times)

figure, axis = plt.subplots(35, 1, figsize=(15,10))
lis=[]

#do not split first column with times
for i in range(1,36):
  var=split.iloc[:, i]
  lis.append(var)

for i in range(len(lis)):
  axis[i].plot(times_converted,convert(lis[i]), 'k')
axis[0].set_title('EEG Signal from distracted driving', {'fontsize':13})

second=split.iloc[:, 2]
third = split.iloc[:, 3]
training=convert(second)
testing=convert(third)

# split a univariate sequence into samples
def split_sequence(sequence, n_steps_in, n_steps_out):
	X, y = list(), list()
	for i in range(len(sequence)):
		# find the end of the pattern
		end_ix = i + n_steps_in
		out_end_ix = end_ix + n_steps_out
		# check exceeds length
		if out_end_ix > len(sequence):
			break
		# combine parts of pattern
		seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]
		X.append(seq_x)
		y.append(seq_y)
	return array(X), array(y)

# define input sequence
raw_seq = training
# choose a number of time steps to predict
n_steps_in, n_steps_out = 50, 400
# split into samples
X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)
# reshape from [samples, timesteps] into [samples, timesteps, features]
n_features = 1
X = X.reshape((X.shape[0], X.shape[1], n_features))

# define model
model = Sequential()
model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))
model.add(LSTM(100, activation='relu'))
model.add(Dense(n_steps_out))
model.summary()

#use mean square error loss to optimize parameters
model.compile(optimizer='adam', loss='mse')

model.fit(X, y, epochs=20, verbose=1)

# predicted terms
x_input = np.array(testing)[0:n_steps_in]
x_input = x_input.reshape((1, n_steps_in, n_features))
yhat = model.predict(x_input, verbose=0)
print(yhat)

yhat_list = yhat.tolist()
sub=yhat_list[0]

float_list=[]
for i in range(len(sub)):
  float_list.append(sub[i])

plt.plot(training)

#print predictions
plt.plot(float_list)